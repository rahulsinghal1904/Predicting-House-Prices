{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install turicreate\nimport turicreate as tc","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting turicreate\n  Downloading turicreate-6.3-cp37-cp37m-manylinux1_x86_64.whl (91.9 MB)\n\u001b[K     |████████████████████████████████| 91.9 MB 3.8 kB/s  eta 0:00:01\n\u001b[?25hCollecting coremltools==3.3\n  Downloading coremltools-3.3-cp37-none-manylinux1_x86_64.whl (3.5 MB)\n\u001b[K     |████████████████████████████████| 3.5 MB 52.8 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: prettytable==0.7.2 in /opt/conda/lib/python3.7/site-packages (from turicreate) (0.7.2)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from turicreate) (1.14.0)\nRequirement already satisfied: decorator>=4.0.9 in /opt/conda/lib/python3.7/site-packages (from turicreate) (4.4.2)\nRequirement already satisfied: pandas>=0.23.2 in /opt/conda/lib/python3.7/site-packages (from turicreate) (1.1.0)\nCollecting resampy==0.2.1\n  Downloading resampy-0.2.1.tar.gz (322 kB)\n\u001b[K     |████████████████████████████████| 322 kB 39.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from turicreate) (1.4.1)\nCollecting tensorflow<=2.0.1,>=2.0.0\n  Downloading tensorflow-2.0.1-cp37-cp37m-manylinux2010_x86_64.whl (86.3 MB)\n\u001b[K     |████████████████████████████████| 86.3 MB 125 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from turicreate) (1.18.5)\nRequirement already satisfied: requests>=2.9.1 in /opt/conda/lib/python3.7/site-packages (from turicreate) (2.23.0)\nRequirement already satisfied: pillow>=5.2.0 in /opt/conda/lib/python3.7/site-packages (from turicreate) (7.2.0)\nRequirement already satisfied: protobuf>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from coremltools==3.3->turicreate) (3.12.4)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.2->turicreate) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.2->turicreate) (2019.3)\nRequirement already satisfied: numba>=0.32 in /opt/conda/lib/python3.7/site-packages (from resampy==0.2.1->turicreate) (0.48.0)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.0.1,>=2.0.0->turicreate) (0.34.2)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.0.1,>=2.0.0->turicreate) (0.9.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.0.1,>=2.0.0->turicreate) (1.1.0)\nCollecting keras-applications>=1.0.8\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 3.6 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.0.1,>=2.0.0->turicreate) (1.1.2)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\nCollecting tensorflow-estimator<2.1.0,>=2.0.0\n  Downloading tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449 kB)\n\u001b[K     |████████████████████████████████| 449 kB 38.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.0.1,>=2.0.0->turicreate) (1.11.2)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.0.1,>=2.0.0->turicreate) (1.31.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.0.1,>=2.0.0->turicreate) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<=2.0.1,>=2.0.0->turicreate) (3.3.0)\nCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nCollecting tensorboard<2.1.0,>=2.0.0\n  Downloading tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 54.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->turicreate) (2020.6.20)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->turicreate) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->turicreate) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->turicreate) (1.24.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.1.0->coremltools==3.3->turicreate) (46.1.3.post20200325)\nRequirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.32->resampy==0.2.1->turicreate) (0.31.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow<=2.0.1,>=2.0.0->turicreate) (2.10.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (3.2.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (0.4.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (1.0.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (1.14.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (1.2.0)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (4.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (3.1.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (0.2.7)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (3.0.1)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<=2.0.1,>=2.0.0->turicreate) (0.4.8)\nBuilding wheels for collected packages: resampy, gast\n  Building wheel for resampy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for resampy: filename=resampy-0.2.1-py3-none-any.whl size=320848 sha256=0cbffd5c66e6171cc8d33cb12244d5e805a6aabb61aae9d5517f6460a8e6a51a\n  Stored in directory: /root/.cache/pip/wheels/71/74/53/d5ceb7c5ee7a168c7d106041863e71ac3273f4a4677743a284\n  Building wheel for gast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=ddcc0ecc1f5482f95b14fac254d021f5f27406e8f0b12661eb64b1c591094e6d\n  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\nSuccessfully built resampy gast\nInstalling collected packages: coremltools, resampy, keras-applications, gast, tensorflow-estimator, astor, tensorboard, tensorflow, turicreate\n  Attempting uninstall: resampy\n    Found existing installation: resampy 0.2.2\n    Uninstalling resampy-0.2.2:\n      Successfully uninstalled resampy-0.2.2\n  Attempting uninstall: gast\n    Found existing installation: gast 0.3.3\n    Uninstalling gast-0.3.3:\n      Successfully uninstalled gast-0.3.3\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.3.0\n","name":"stdout"},{"output_type":"stream","text":"    Uninstalling tensorflow-estimator-2.3.0:\n      Successfully uninstalled tensorflow-estimator-2.3.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.3.0\n    Uninstalling tensorboard-2.3.0:\n      Successfully uninstalled tensorboard-2.3.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.3.0\n    Uninstalling tensorflow-2.3.0:\n      Successfully uninstalled tensorflow-2.3.0\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\ntensorflow-probability 0.11.0 requires gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\nlibrosa 0.8.0 requires resampy>=0.2.2, but you'll have resampy 0.2.1 which is incompatible.\u001b[0m\nSuccessfully installed astor-0.8.1 coremltools-3.3 gast-0.2.2 keras-applications-1.0.8 resampy-0.2.1 tensorboard-2.0.2 tensorflow-2.0.1 tensorflow-estimator-2.0.1 turicreate-6.3\n\u001b[33mWARNING: You are using pip version 20.2.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We will use LASSO to select features, building on a pre-implemented solver for LASSO \n1.Run LASSO with different L1 penalties.\n2.Choose best L1 penalty using a validation set.\n3.Choose best L1 penalty using a validation set, with additional constraint on the size of subset."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales= tc.SFrame('../input/house-data')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import log, sqrt\nsales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\nsales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\nsales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n\n# In the dataset, 'floors' was defined with type string, \n# so we'll convert them to float, before creating a new feature.\nsales['floors'] = sales['floors'].astype(float) \nsales['floors_square'] = sales['floors']*sales['floors']","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\nOn the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = ['bedrooms', 'bedrooms_square',\n            'bathrooms',\n            'sqft_living', 'sqft_living_sqrt',\n            'sqft_lot', 'sqft_lot_sqrt',\n            'floors', 'floors_square',\n            'waterfront', 'view', 'condition', 'grade',\n            'sqft_above',\n            'sqft_basement',\n            'yr_built', 'yr_renovated']","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_all = tc.linear_regression.create(sales, target='price', features=all_features,\n                                              validation_set=None, \n                                              l2_penalty=0., l1_penalty=1e10)","execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Linear regression:","text/html":"<pre>Linear regression:</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"--------------------------------------------------------","text/html":"<pre>--------------------------------------------------------</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of examples          : 21613","text/html":"<pre>Number of examples          : 21613</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of features          : 17","text/html":"<pre>Number of features          : 17</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of unpacked features : 17","text/html":"<pre>Number of unpacked features : 17</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Number of coefficients    : 18","text/html":"<pre>Number of coefficients    : 18</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Starting Accelerated Gradient (FISTA)","text/html":"<pre>Starting Accelerated Gradient (FISTA)</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"--------------------------------------------------------","text/html":"<pre>--------------------------------------------------------</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tuning step size. First iteration could take longer than subsequent iterations.","text/html":"<pre>Tuning step size. First iteration could take longer than subsequent iterations.</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"+-----------+----------+-----------+--------------+--------------------+---------------------------------+","text/html":"<pre>+-----------+----------+-----------+--------------+--------------------+---------------------------------+</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| Iteration | Passes   | Step size | Elapsed Time | Training Max Error | Training Root-Mean-Square Error |","text/html":"<pre>| Iteration | Passes   | Step size | Elapsed Time | Training Max Error | Training Root-Mean-Square Error |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"+-----------+----------+-----------+--------------+--------------------+---------------------------------+","text/html":"<pre>+-----------+----------+-----------+--------------+--------------------+---------------------------------+</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 0         | 1        | 1.000000  | 1.015997     | 7700000.000000     | 653047.733994                   |","text/html":"<pre>| 0         | 1        | 1.000000  | 1.015997     | 7700000.000000     | 653047.733994                   |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 1         | 2        | 0.000002  | 1.312086     | 6962915.603493     | 426631.749026                   |","text/html":"<pre>| 1         | 2        | 0.000002  | 1.312086     | 6962915.603493     | 426631.749026                   |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 2         | 3        | 0.000002  | 1.344461     | 6843144.200219     | 392488.929838                   |","text/html":"<pre>| 2         | 3        | 0.000002  | 1.344461     | 6843144.200219     | 392488.929838                   |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 3         | 4        | 0.000002  | 1.371545     | 6831900.032123     | 385340.166783                   |","text/html":"<pre>| 3         | 4        | 0.000002  | 1.371545     | 6831900.032123     | 385340.166783                   |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 4         | 5        | 0.000002  | 1.398884     | 6847166.848958     | 384842.383767                   |","text/html":"<pre>| 4         | 5        | 0.000002  | 1.398884     | 6847166.848958     | 384842.383767                   |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 5         | 6        | 0.000002  | 1.424820     | 6869667.895833     | 385998.458623                   |","text/html":"<pre>| 5         | 6        | 0.000002  | 1.424820     | 6869667.895833     | 385998.458623                   |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"| 10        | 11       | 0.000002  | 1.559983     | 6842123.232651     | 364204.576180                   |","text/html":"<pre>| 10        | 11       | 0.000002  | 1.559983     | 6842123.232651     | 364204.576180                   |</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"+-----------+----------+-----------+--------------+--------------------+---------------------------------+","text/html":"<pre>+-----------+----------+-----------+--------------+--------------------+---------------------------------+</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Completed (Iteration limit reached).","text/html":"<pre>Completed (Iteration limit reached).</pre>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"This model may not be optimal. To improve it, consider increasing `max_iterations`.","text/html":"<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# non_zero_weight = model_all.get(\"coefficients\")[\"value\"]\nnon_zero_weight = model_all.coefficients[model_all.coefficients[\"value\"] > 0]\nnon_zero_weight.print_rows(num_rows=20)","execution_count":8,"outputs":[{"output_type":"stream","text":"+------------------+-------+--------------------+--------+\n|       name       | index |       value        | stderr |\n+------------------+-------+--------------------+--------+\n|   (intercept)    |  None | 274873.0559504957  |  None  |\n|    bathrooms     |  None | 8468.531086910072  |  None  |\n|   sqft_living    |  None | 24.420720982445214 |  None  |\n| sqft_living_sqrt |  None | 350.0605533860648  |  None  |\n|      grade       |  None | 842.0680348976282  |  None  |\n|    sqft_above    |  None | 20.024722417091304 |  None  |\n+------------------+-------+--------------------+--------+\n[6 rows x 4 columns]\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n\n1.Split our sales data into 2 sets: training and test\n2.Further split our training data into two sets: train, validation\n3.Be very careful that you use seed = 1 to ensure you get the same answer!"},{"metadata":{"trusted":true},"cell_type":"code","source":"(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pprint \n\nvalidation_rss = {}\nfor l1_penalty in np.logspace(1, 7, num=13):\n    model = tc.linear_regression.create(training, target='price', features=all_features,\n                                              validation_set=None, verbose = False,\n                                              l2_penalty=0., l1_penalty=l1_penalty)\n    predictions = model.predict(validation)\n    residuals = validation['price'] - predictions\n    rss = sum(residuals**2)\n    validation_rss[l1_penalty] = rss\n\n# pprint.pprint(result_dict)\nprint (min(validation_rss.items(), key=lambda x: x[1]) )","execution_count":10,"outputs":[{"output_type":"stream","text":"(10.0, 625766285142461.2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_test = tc.linear_regression.create(training, target='price', features=all_features,\n                                              validation_set=None, verbose = False,\n                                              l2_penalty=0., l1_penalty=10.0)\npredictions_test = model.predict(testing)\nresiduals_test = testing['price'] - predictions_test\nrss_test = sum(residuals_test**2)\nprint (rss_test)","execution_count":11,"outputs":[{"output_type":"stream","text":"156972779668688.7\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_zero_weight_test = model_test.coefficients[model_test.coefficients[\"value\"] > 0]\nprint (model_test.coefficients[\"value\"].nnz())\nnon_zero_weight_test.print_rows(num_rows=20)","execution_count":12,"outputs":[{"output_type":"stream","text":"18\n+------------------+-------+----------------------+--------+\n|       name       | index |        value         | stderr |\n+------------------+-------+----------------------+--------+\n|   (intercept)    |  None |  18993.427212770577  |  None  |\n|     bedrooms     |  None |  7936.967679031306   |  None  |\n| bedrooms_square  |  None |   936.993368193299   |  None  |\n|    bathrooms     |  None |  25409.58893412067   |  None  |\n|   sqft_living    |  None |  39.11513637970762   |  None  |\n| sqft_living_sqrt |  None |  1124.6502128077207  |  None  |\n|     sqft_lot     |  None | 0.003483618222989743 |  None  |\n|  sqft_lot_sqrt   |  None |  148.2583910114082   |  None  |\n|      floors      |  None |  21204.33546695013   |  None  |\n|  floors_square   |  None |  12915.524336072436  |  None  |\n|    waterfront    |  None |  601905.5945452718   |  None  |\n|       view       |  None |  93312.85731187189   |  None  |\n|    condition     |  None |  6609.035712447216   |  None  |\n|      grade       |  None |  6206.939991880551   |  None  |\n|    sqft_above    |  None |  43.28705341933558   |  None  |\n|  sqft_basement   |  None |  122.36782753411931  |  None  |\n|     yr_built     |  None |  9.433635393724884   |  None  |\n|   yr_renovated   |  None |  56.072003448822386  |  None  |\n+------------------+-------+----------------------+--------+\n[18 rows x 4 columns]\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Limit the number of nonzero weights\nWhat if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them.\n\nIn this section, you are going to implement a simple, two phase procedure to achive this goal:\n\nExplore a large range of l1_penalty values to find a narrow region of l1_penalty values where models are likely to have the desired number of non-zero weights.\nFurther explore the narrow region you found to find a good value for l1_penalty that achieves the desired sparsity. Here, we will again use a validation set to choose the best value for l1_penalty."},{"metadata":{"trusted":true},"cell_type":"code","source":"max_nonzeros = 7","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring the larger range of values to find a narrow range with the desired sparsity\nLet's define a wide range of possible l1_penalty_values:"},{"metadata":{"trusted":true},"cell_type":"code","source":"l1_penalty_values = np.logspace(8, 10, num=20)\nprint (l1_penalty_values)","execution_count":14,"outputs":[{"output_type":"stream","text":"[1.00000000e+08 1.27427499e+08 1.62377674e+08 2.06913808e+08\n 2.63665090e+08 3.35981829e+08 4.28133240e+08 5.45559478e+08\n 6.95192796e+08 8.85866790e+08 1.12883789e+09 1.43844989e+09\n 1.83298071e+09 2.33572147e+09 2.97635144e+09 3.79269019e+09\n 4.83293024e+09 6.15848211e+09 7.84759970e+09 1.00000000e+10]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now, implement a loop that search through this space of possible l1_penalty values:\n\nFor l1_penalty in np.logspace(8, 10, num=20):\nFit a regression model with a given l1_penalty on TRAIN data. Specify l1_penalty=l1_penalty and l2_penalty=0. in the parameter list. When you call linear_regression.create() make sure you set validation_set = None\nExtract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\nHint: model['coefficients']['value'] gives you an SArray with the parameters you learned. If you call the method .nnz() on it, you will find the number of non-zero parameters!"},{"metadata":{"trusted":true},"cell_type":"code","source":"coef_dict = {}\nfor l1_penalty in l1_penalty_values:\n    model = tc.linear_regression.create(training, target ='price', features=all_features,\n                                              validation_set=None, verbose=None,\n                                              l2_penalty=0., l1_penalty=l1_penalty)\n    coef_dict[l1_penalty] = model.coefficients['value'].nnz()","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pprint.pprint(coef_dict)","execution_count":17,"outputs":[{"output_type":"stream","text":"{100000000.0: 18,\n 127427498.57031322: 18,\n 162377673.91887242: 18,\n 206913808.111479: 18,\n 263665089.87303555: 17,\n 335981828.6283788: 17,\n 428133239.8719396: 17,\n 545559478.1168514: 17,\n 695192796.1775591: 17,\n 885866790.4100832: 16,\n 1128837891.6846883: 15,\n 1438449888.2876658: 15,\n 1832980710.8324375: 13,\n 2335721469.0901213: 12,\n 2976351441.6313133: 10,\n 3792690190.7322536: 6,\n 4832930238.571753: 5,\n 6158482110.6602545: 3,\n 7847599703.514623: 1,\n 10000000000.0: 1}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"l1_penalty_min = 2976351441.6313128\nl1_penalty_max = 3792690190.7322536","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set\nWe will now explore the narrow region of l1_penalty values we found:"},{"metadata":{"trusted":true},"cell_type":"code","source":"l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For l1_penalty in np.linspace(l1_penalty_min,l1_penalty_max,20):\nFit a regression model with a given l1_penalty on TRAIN data. Specify l1_penalty=l1_penalty and l2_penalty=0. in the parameter list. When you call linear_regression.create() make sure you set validation_set = None\nMeasure the RSS of the learned model on the VALIDATION set\nFind the model that the lowest RSS on the VALIDATION set and has sparsity equal to max_nonzero."},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_rss = {}\nfor l1_penalty in l1_penalty_values:\n    model = tc.linear_regression.create(training, target='price', features=all_features,\n                                              validation_set=None, verbose = False,\n                                              l2_penalty=0., l1_penalty=l1_penalty)\n    predictions = model.predict(validation)\n    residuals = validation['price'] - predictions\n    rss = sum(residuals**2)\n    validation_rss[l1_penalty] = rss, model.coefficients['value'].nnz()\n    ","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bestRSS=0\n\nfor k,v in validation_rss.items():    \n    if (v[1] == max_nonzeros) and (v[0] < bestRSS):\n        bestRSS = v[0]\n        bestl1 = k\n        \nprint (bestRSS, bestl1)","execution_count":25,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'bestl1' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-52a70ebd822a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbestl1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbestRSS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbestl1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'bestl1' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}